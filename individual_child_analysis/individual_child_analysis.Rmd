---
title: "Individual_Child_Analysis"
author: "Masoud Jasbi & Debbie Odufuwa"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(childesr)
library(tidyverse)
library(feather)
library(dplyr)
library(ggplot2)
```

# Loading Data from Childes-DB

```{r ChildesDBimports}
# Loading all data from Eng-NA and Eng-UK Corpora
individual_english_tokens <- get_tokens(
  collection = c("Eng-NA","Eng-UK"),
  role = c("target_child"),
  token = "*")
```

# Token PreProcessing

## Lowercasing
```{r lowerCase}
individual_english_tokens$gloss <- individual_english_tokens$gloss %>% tolower()
```

# Token Processing

## Exclusions
```{r exclusionsTokens}
# Count the tokens before exclusions
initial <- nrow(individual_english_tokens)

# Number of children before exclusions
n_chi_initial <-
  individual_english_tokens$target_child_id %>% unique() %>% length()

english_tokens <- individual_english_tokens # temporary line

# Count the tokens after excluding unintelligible ones
unintels <- nrow(english_tokens)

# Number of children after excluding unintelligible tokens
n_chi_unintels <-
  english_tokens$target_child_id %>% unique() %>% length()


# Remove other unlikely words/transcription mistakes such as "vocalizing"
# Vector of ids
unreasonable_id <- c(10927346, 10937151, 11379328, 11382701, 10972379, 11030373, 11030647, 4030824, 10114202)
# First three are "vocalizes" or "vocalizing", "classic", "vocalizes", " references", "transcribed"
english_tokens <- 
  english_tokens %>%
  filter(!id %in% unreasonable_id)

# Count the tokens after excluding babbles and unreasonable words
babble_unreasonable <- nrow(english_tokens)

# Number of children after excluding babbles/unreasonable tokens
n_chi_babble_unreason <-
  english_tokens$target_child_id %>% unique() %>% length()

# Remove NAs target_child_age
english_tokens <- 
  english_tokens %>% drop_na(target_child_age)

# Count the tokens after removing NA tokens
nas <- nrow(english_tokens)

# Number of children after excluding NAs
n_chi_nas <-
  english_tokens$target_child_id %>% unique() %>% length()

# Take out data for the age range above 6 years
english_tokens <-
  english_tokens %>%
  filter(target_child_age < 72)

# Count the tokens after excluding the below 1 and older than 6 age range
age_ex <- nrow(english_tokens)

# Number of children left after exclusions
n_chi_age <-
  english_tokens$target_child_id %>% unique() %>% length()

# Record the dataframe of exclusions
exclusions <-
  data.frame (
    initial = initial,
    after_unintels = unintels,
    after_babbles = babble_unreasonable,
    after_nas = nas,
    after_age = age_ex,
    unintelligible = initial - unintels,
    babbles = unintels - babble_unreasonable,
    missing = babble_unreasonable - nas,
    age = nas - age_ex,
    n_chi_total = n_chi_initial,
    n_chi_unintels = n_chi_unintels,
    n_chi_babble = n_chi_babble_unreason,
    n_chi_nas = n_chi_nas,
    n_chi_age = n_chi_age)
```

## Saving the Data
```{r savingData}
# Save the exclusion data in a file as well as the final data
#write_csv(exclusions, "../raw_data/token_exclusions.csv")
#write_feather(english_tokens, "../raw_data/english_tokens.feather")
```

## Coding Speaker Roles
```{r}
# Collapse mothers and fathers into parents
english_tokens$speaker <- "parent"
english_tokens$speaker[english_tokens$speaker_role=="Target_Child"] <- "child"
```

## Coding Age
```{r age}
# Bin age data per month
english_tokens$age <- english_tokens$target_child_age %>% floor()
```

## Grouping Utterance Types
```{r utterance_types}
# Prepare the utterance_type categories for this study based on the utterance_types in childes-db
## Categories: declarative, impertaive, interrogative, and other
english_tokens$utterance_type <-
  recode(english_tokens$utterance_type, 
         question = "interrogative",
         `broken for coding`="other",
          `imperative_emphatic` = "imperative",
         interruption = "other",
         `interruption question` = "interrogative",
         `missing CA terminator` = "other",
         `no break TCU continuation` = "other",
         `question exclamation` = "interrogative",
         `quotation next line` = "other",
         `quotation precedes` = "other",
         `self interruption` = "other",
         `self interruption question` = "interrogative",
         `trail off` = "other",
         `trail off question` = "interrogative"
         )
```

## Contractions
```{r}
# Change 'cannot' to 'can' 'not' separated across rows
# change 'cannot' to to 'cann'ot' and add this pattern to code below
english_tokens_contract <-
  english_tokens %>%
  mutate(gloss = str_replace(gloss, "cannot", "cann'ot"))

```

```{r}
# Change 'can't' to 'cann't'
english_tokens_contract <- 
  english_tokens_contract %>%
  mutate(gloss = str_replace(gloss, "can't", "cann't"))

```

```{r}
# Change 'won't' to 'wont' so it doesn't get picked up by the pattern recognition below
english_tokens_contract <-
  english_tokens_contract %>%
  mutate(gloss = str_replace(gloss, "won't", "wont"))

```

```{r}
# Define the patterns and exceptions
patterns <- c("n't", "'ll", "'s", "'d", "'m", "'re")
#exceptions <- c("can't", "won't", "cannot")

# filter based on the patterns to have one dataframe of contracations and one without any contractions

# create two separate dataframes of the contractions
contractions <-
  english_tokens_contract %>%
  filter(str_detect(gloss, "n't|'ll|'s|'d|'m|'re|n'ot|'ve"))

contracted <- contractions

# Remove contractions from the original list

english_tokens_contract <-
  english_tokens_contract %>%
  filter(!str_detect(gloss, "n't|'ll|'s|'d|'m|'re|n'ot|'ve"))

# in one remove the contractions

contracted$gloss <- str_remove_all(contracted$gloss, "n't|'ll|'s|'d|'m|'re|n'ot|'ve")

# in the other remove the contracted

contractions$gloss <- str_extract(contractions$gloss, "n't|'ll|'s|'d|'m|'re|n'ot|'ve")

# put the dataframes back together

contracted_contractions <-
  rbind(contracted, contractions)

# bind them with the original that was without contractions

english_tokens_contract <-
  rbind(english_tokens_contract, contracted_contractions)

# replace n'ot with not
english_tokens_contract <-
  english_tokens_contract %>%
  mutate(gloss = str_replace(gloss, "n'ot", "not"))

# replace wont with won't
english_tokens_contract <-
  english_tokens_contract %>%
  mutate(gloss = str_replace(gloss, "wont", "won't"))

# english_tokens_contract is what you want to run the functions on to analyze contractions seperate from their stems
```

# Defining Function Words in English
```{r NLTK list}
c('couldn', "couldn't",
 "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shouldn', "shouldn't", "won't", 'wouldn', "wouldn't")
```

```{r FunctionWords}
english_tokens_contract$word <- "nonfunction"

function_words_contract <- c("no", "not", "n't", "'ll", "'s", "'d", "'m", "yes", "and", "or", "if", "nor", "therefore", "none", "some", "each", "every", "all", "most", "few", "many", "several", "few", "both", "everyone", "someone", "somebody", "everybody", "nonone", "everything", "something", "nowhere", "somewhere", "everywhere", "more", "less", "much", "most", "least", "than", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "first", "second", "third", "fourth", "fifth", "sixth", "seventh", "eighth", "nineth", "tenth", "last", "can", "could", "need", "may", "might", "should", "ought", "must", "maybe", "perhaps", "shall", "will", "would", "won't", "any", "anyone", "anything", "anywhere", "anything", "anyway", "anyways", "ever", "yet", "the", "a", "an", "this", "that", "these", "those", "always", "usually", "seldom", "never", "sometimes", "often", "once", "twice", "now", "while", "after", "before", "then", "until", "since", "whenever", "during", "who", "when", "what", "whose", "where", "how", "why", "whom", "on", "in", "out", "up", "down", "under", "above", "below", "along", "over", "behind", "across", "beside", "between", "beyond", "into", "near", "onto", "toward", "here", "through", "here", "there", "because", "but", "although", "am", "is", "are", "was", "were", "be", "been", "being", "have", "has", "had", "having", "do", "does", "did", "doing", "i", "you", "we", "he", "she", "they", "me", "us", "her", "him", "them", "my", "your", "our", "his", "their", "its", "mine", "yours", "ours", "hers", "theirs", "myself", "yourself", "ourselves", "himself", "herself", "yourselves", "themselves", "it", "itself", "again", "too", "also", "another", "other", "others", "still", "only", "just", "even", "indeed", "either", "neither", "whether", "as", "else", "almost", "already", "except", "for", "from", "instead", "such", "with", "without", "about", "by", "very", "unless", "to", "of", "would", "at", "against")

for (x in function_words_contract){
  english_tokens_contract$word[english_tokens_contract$gloss==x] <- x
}


# Create separate function words that do include the function words as their own words
english_tokens$word <- "nonfunction"

function_words <- c("no", "not", "I’m", "you’re", "he’s", "she’s", "it’s", "we’re", "they’re","i’ve", "you’ve", "we’ve", "they’ve", "i’d", "you’d", "he’d", "she’d", "we’d", "they’d", "i’ll", "you’ll", "he’ll", "she’ll", "we’ll", "they’ll", "don’t", "doesn’t", "didn’t", "isn’t", "aren’t", "wasn’t", "weren’t", "haven’t", "hasn’t", "hadn’t","can’t", "couldn’t", "won’t", "wouldn’t", "shouldn’t", "yes", "and", "or", "if", "nor", "therefore", "none", "some", "each", "every", "all", "most", "few", "many", "several", "few", "both", "everyone", "someone", "somebody", "everybody", "nonone", "everything", "something", "nowhere", "somewhere", "everywhere", "more", "less", "much", "most", "least", "than", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "first", "second", "third", "fourth", "fifth", "sixth", "seventh", "eighth", "nineth", "tenth", "last", "can", "could", "need", "may", "might", "should", "ought", "must", "maybe", "perhaps", "shall", "will", "would", "won't", "any", "anyone", "anything", "anywhere", "anything", "anyway", "anyways", "ever", "yet", "the", "a", "an", "this", "that", "these", "those", "always", "usually", "seldom", "never", "sometimes", "often", "once", "twice", "now", "while", "after", "before", "then", "until", "since", "whenever", "during", "who", "when", "what", "whose", "where", "how", "why", "whom", "on", "in", "out", "up", "down", "under", "above", "below", "along", "over", "behind", "across", "beside", "between", "beyond", "into", "near", "onto", "toward", "here", "through", "here", "there", "because", "but", "although", "am", "is", "are", "was", "were", "be", "been", "being", "have", "has", "had", "having", "do", "does", "did", "doing", "i", "you", "we", "he", "she", "they", "me", "us", "her", "him", "them", "my", "your", "our", "his", "their", "its", "mine", "yours", "ours", "hers", "theirs", "myself", "yourself", "ourselves", "himself", "herself", "yourselves", "themselves", "it", "itself", "again", "too", "also", "another", "other", "others", "still", "only", "just", "even", "indeed", "either", "neither", "whether", "as", "else", "almost", "already", "except", "for", "from", "instead", "such", "with", "without", "about", "by", "very", "unless", "to", "of", "would", "at", "against")

for (x in function_words){
  english_tokens$word[english_tokens$gloss==x] <- x
}
```


# Evaluating Production of Individual Children

## Selecting Children that Have Dense Data Between Ages 1-4
```{r count-tokens-per-child}
# Count number of tokens for each child
library(dplyr)

tokens_per_child <- english_tokens_contract %>%
  filter(target_child_age >= 12 & target_child_age <= 48) %>%
  group_by(corpus_name, target_child_name, speaker = "child") %>%
  summarise(token_count = n(), .groups = "drop") %>%
  arrange(desc(token_count))
tokens_per_child

# Ten children who produced the most tokens between 1-4
top_ten_children <- head(tokens_per_child, 10)
top_ten_children
```

## Histograms

```{r}
# Create bins for age: 12-15, 16-19, ..., up to 44-47, 48 (all ages included in 12-48)
age_bins <- seq(12, 48, by = 4)
age_labels <- paste0(age_bins[-length(age_bins)], "-", age_bins[-1] - 1)
age_labels[length(age_labels)] <- paste0(age_bins[length(age_bins)-1], "-", age_bins[length(age_bins)])

# Assign each token to an age bin
tokens_binned <- english_tokens_contract %>%
  filter(
    target_child_age >= 12 & target_child_age <= 48,
    target_child_name %in% top_ten_children$target_child_name,
    speaker == "child"
  ) %>%
  mutate(age_bin = cut(
    target_child_age,
    breaks = age_bins,
    labels = age_labels,
    include.lowest = TRUE,
    right = FALSE
  ))

# Count tokens per child per age bin
tokens_per_bin <- tokens_binned %>%
  group_by(target_child_name, age_bin) %>%
  summarise(token_count = n(), .groups = "drop")

# Find the top child for each bin
top_child_per_bin <- tokens_per_bin %>%
  group_by(age_bin) %>%
  top_n(1, token_count) %>%
  ungroup()

# Plot: Distribution of token counts per age bin for each child
library(ggplot2)
ggplot(tokens_per_bin, aes(x = age_bin, y = token_count, fill = target_child_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Token Production by Top Children in Each Age Bin (12-48 months)",
    x = "Age Bin (months)",
    y = "Token Count",
    fill = "Child"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

# Additionally, show which child is the top producer per bin
top_child_table <- top_child_per_bin %>%
  arrange(age_bin) %>%
  select(age_bin, target_child_name, token_count)
knitr::kable(top_child_table, caption = "Top Child Producer per Age Bin (12-48 months)")
```

## Density Plots
```{r}
# Density plots: Age distribution of tokens produced by each top ten child

library(ggplot2)
library(dplyr)

# Filter to relevant tokens: 12-48 months, top ten children, child speaker only
tokens_top_ten <- english_tokens_contract %>%
  filter(
    target_child_age >= 12 & target_child_age <= 48, # not correct / limits the tokens
    target_child_name %in% top_ten_children$target_child_name,
    speaker == "child"
  )

# Density plot of target_child_age for each child (different color per child)
ggplot(
  tokens_top_ten,
  aes(x = target_child_age, fill = target_child_name)
) +
  geom_density(alpha = 0.5, color = NA) +
  labs(
    title = "Age Distribution of Token Production: Top Ten Children (12-48 months)",
    x = "Age (months)",
    y = "Density",
    fill = "Child"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Optionally, show the densities faceted by child
ggplot(
  tokens_top_ten,
  aes(x = target_child_age)
) +
  geom_density(fill = "deepskyblue", alpha = 0.6) +
  facet_wrap(~ target_child_name, scales = "free_y") +
  labs(
    title = "Age Distribution of Token Production: Top Ten Children (12-48 months)",
    x = "Age (months)",
    y = "Density"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## Cumulative Token Trajectory Plots for Selected Children and Function Words
```{r cumulative_ppt_trajectories, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
library(ggplot2)
library(dplyr)

# Choose selected function words to plot: pick a few representative examples
selected_function_words <- c("the", "and", "no", "not", "i", "you", "can", "have", "do", "it")

# Filter data for top ten children and selected function words, ages 12-48 months
child_word_data <- english_tokens_contract %>%
  filter(
    word %in% selected_function_words,
    target_child_age >= 12 & target_child_age <= 48,
    target_child_name %in% top_ten_children$target_child_name
  ) %>%
  arrange(target_child_name, word, target_child_age)

# Compute cumulative tokens per child, per word, over time (by age in months)
cumulative_traj <- child_word_data %>%
  group_by(word, target_child_name) %>%
  arrange(target_child_age) %>%
  mutate(cum_count = row_number()) %>%
  group_by(word, target_child_name, target_child_age) %>%
  summarise(cumulative = max(cum_count), .groups = "drop")

# Plot: One panel per function word, lines for each child
ggplot(cumulative_traj, aes(x = target_child_age, y = cumulative, color = target_child_name)) +
  geom_line(size=1) +
  facet_wrap(~ word, ncol=2, scales = "free_y") +
  scale_color_brewer(palette = "Set1") +
  labs(
    title = "Cumulative Token Trajectories for Selected Function Words (lines = children)",
    x = "Age (months)",
    y = "Cumulative Token Count",
    color = "Child"
  ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    strip.text = element_text(size=12),
    axis.text = element_text(size=10)
  )
```

## Cumulative PPT Trajectories of Selected Children and Parents
```{r cumulative_ppt_trajectories, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
library(ggplot2)
library(dplyr)

# Use the same function word set as above
selected_function_words <- c("the", "and", "no", "not", "i", "you", "can", "have", "do", "it")

# Restrict data to top ten children and desired function words
child_relfreq <- english_tokens_contract %>%
  filter(
    word %in% selected_function_words,
    target_child_name %in% top_ten_children$target_child_name
  ) %>%
  group_by(word, target_child_age, speaker, target_child_name) %>%
  summarise(freq = n(), .groups = "drop") %>%
  group_by(speaker, target_child_age, target_child_name) %>%
  mutate(total = sum(freq),
         relfreq = freq / sum(freq),
         ppt = relfreq * 1000) %>%
  group_by(word, speaker, target_child_name) %>%
  arrange(target_child_age) %>%
  mutate(
    cum_freq = cumsum(freq),
    cum_total = cumsum(total),
    cumulative_relfreq = cumsum(freq) / cumsum(total),
    cumulative_ppt = cumulative_relfreq * 1000
  ) %>%
  ungroup()

plots_list <- lapply(selected_function_words, function(fw) {
  word_df <- child_relfreq %>%
    filter(word == fw)
  
  # Only children speakers with at least 5 data points for this word
  child_counts <- word_df %>%
    filter(speaker == "target_child") %>%
    group_by(target_child_name) %>%
    summarise(n_points = n(), .groups = "drop") %>%
    filter(n_points >= 5)
  
  word_df_filtered <- word_df %>%
    filter(!(
      speaker == "target_child" &
      !(target_child_name %in% child_counts$target_child_name)
    ))
  
  if (nrow(word_df_filtered) == 0) {
    return(NULL)
  }
  ggplot(word_df_filtered, aes(target_child_age, cumulative_ppt, color = speaker)) +
    geom_point() +
    geom_line() +
    facet_wrap(~ target_child_name) +
    theme_bw() +
    labs(title = paste("Cumulative Relative Frequency of Function Word:", paste0(toupper(substring(fw, 1, 1)), substring(fw, 2))),
         x = "Age (months)",
         y = "Cumulative ppt",
         color = "Speaker")
})

for (p in plots_list) {
  if (!is.null(p)) print(p)
}
```

## Cumulative PPT Trajectories of Children Who Produced Most Tokens (Individual Plots)
```{r cumulative_ppt_trajectories, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}
library(ggplot2)
library(dplyr)

# Use the same function word set as above
selected_function_words <- c("the", "and", "no", "not", "i", "you", "can", "have", "do", "it")

# Restrict data to top ten children and desired function words, and only keep speaker == "child"
child_relfreq <-
  english_tokens_contract %>%
  filter(word %in% selected_function_words,
         target_child_name %in% top_ten_children$target_child_name,
         speaker == "child") %>%
  group_by(word, target_child_age, target_child_name) %>%
  summarise(freq = n(), .groups = "drop") %>%
  group_by(target_child_age, target_child_name) %>%
  mutate(total = sum(freq),
         relfreq = freq / sum(freq),
         ppt = relfreq * 1000) %>%
  group_by(word, target_child_name) %>%
  arrange(target_child_age) %>%
  mutate(cum_freq = cumsum(freq),
         cum_total = cumsum(total),
         cumulative_relfreq = cumsum(freq) / cumsum(total),
         cumulative_ppt = cumulative_relfreq * 1000) %>%
  ungroup()

plots_list <- lapply(selected_function_words, function(fw) {
  word_df <- child_relfreq %>%
    filter(word == fw)
  
  # Only children with at least 5 data points for this word
  child_counts <- word_df %>%
    group_by(target_child_name) %>%
    summarise(n_points = n(), .groups = "drop") %>%
    filter(n_points >= 5)
  
  word_df_filtered <- word_df %>%
    filter(target_child_name %in% child_counts$target_child_name)
  
  if (nrow(word_df_filtered) == 0) {
    return(NULL)
  }
  ggplot(word_df_filtered, aes(target_child_age, cumulative_ppt, color = target_child_name)) +
    geom_point() +
    geom_line() +
    theme_bw() +
    labs(title = paste("Cumulative Relative Frequency for Function Word:", paste0(toupper(substring(fw, 1, 1)), substring(fw, 2))),
         x = "Age (months)",
         y = "Cumulative ppt",
         color = "Child")
})

for (p in plots_list) {
  if (!is.null(p)) print(p)
}
```

## Cumulative PPT Trajectories of Children Who Produced Most Tokens
```{r cumulative_ppt_trajectories, warning=FALSE, message=FALSE, fig.width=10, fig.height=10}
library(ggplot2)
library(dplyr)

# Use the same function word set as above
selected_function_words <- c("the", "and", "no", "not", "i", "you", "can", "have", "do", "it")

# Restrict data to top ten children and desired function words, and only keep speaker == "child"
child_relfreq <- english_tokens_contract %>%
  filter(word %in% selected_function_words,
         target_child_name %in% top_ten_children$target_child_name,
         speaker == "child") %>%
  group_by(word, target_child_age, target_child_name) %>%
  summarise(freq = n(), .groups = "drop") %>%
  group_by(target_child_age, target_child_name) %>%
  mutate(total = sum(freq),
         relfreq = freq / sum(freq),
         ppt = relfreq * 1000) %>%
  group_by(word, target_child_name) %>%
  arrange(target_child_age) %>%
  mutate(cum_freq = cumsum(freq),
         cum_total = cumsum(total),
         cumulative_relfreq = cumsum(freq) / cumsum(total),
         cumulative_ppt = cumulative_relfreq * 1000) %>%
  ungroup()

# Plot: One panel per function word, with lines for each child
ggplot(child_relfreq, aes(x = target_child_age, y = cumulative_ppt, color = target_child_name, group = target_child_name)) +
  geom_line(size = 1) +
  facet_wrap(~ word, ncol = 2, scales = "free_y") +
  theme_bw() +
  labs(
    #title = "Cumulative Relative Frequency for Selected Function Words",
    x = "Age (months)",
    y = "Cumulative PPT",
    color = "Child"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    strip.text = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "bottom"
  )
```


## Distribution of Function Word Production
```{r}
# Distribution of Function Word Production

# Filter to relevant tokens for selected function words and child speakers
tokens_function_words <- english_tokens_contract %>%
  filter(
    word %in% selected_function_words,
    target_child_name %in% top_ten_children$target_child_name,
    speaker == "child"
  )

# 1. Density plot: Distribution of function word token production by age, per word, for top ten children.
ggplot(
  tokens_function_words,
  aes(x = target_child_age, fill = target_child_name)
) +
  geom_density(alpha = 0.5, color = NA) +
  facet_wrap(~ word, ncol = 2, scales = "free_y") +
  labs(
    title = "Distribution of Function Word Production by Child (Per Function Word)",
    x = "Age (months)",
    y = "Density",
    fill = "Child"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12)
  )

# 2. Density plot: Distribution of function word production by age, separate panel for each child
ggplot(
  tokens_function_words,
  aes(x = target_child_age, fill = word)
) +
  geom_density(alpha = 0.5, color = NA) +
  facet_wrap(~ target_child_name, ncol = 2, scales = "free_y") +
  labs(
    title = "Distribution of Function Word Production by Child",
    x = "Age (months)",
    y = "Density",
    fill = "Function Word"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12)
  )
```






# Other (Unused Plots and Code)
## Determining which corpora and children have enough data
<!-- ```{r} -->
<!-- # Target Age Data Range: 12-36 months -->
<!-- individual_children <- get_participants( -->
<!--   collection = "Eng-NA", -->
<!--   role = c("target_child")) -->

<!-- individual_children |>  -->
<!--   select(name, corpus_name, min_age, max_age) |> -->
<!--   filter(!is.na(name), -->
<!--          min_age <= 18, -->
<!--          max_age >= 20, -->
<!--          !corpus_name %in% c("NewmanRatner", "Braunwald", "Brown", -->
<!--                              "McCune", "Brent", "Davis-CDI", -->
<!--                              "StanfordEnglish", "Peters", "Rollins", -->
<!--                              "Feldman", "Tardif", "Soderstrom", -->
<!--                              "Bernstein", "Menn")) -->

<!-- # NewmanRatner : Child not as involved in conversation -->
<!-- # Braunwald : Found to have developmental disorder -->
<!-- # Brown : Late development -->
<!-- # McCune : most child language utterances not transcribed -->
<!-- # Brent: some data not transcribed; most data cuts off around 12-14 months of age -->
<!-- # Davis-CDI : children are just reciting words -->
<!-- # StanfordEnglish : data not transcribed -->
<!-- # Peters : data labelled weirdly -->
<!-- # Rollins : only the mother speaks -->
<!-- # Felman : child role not labelled or annotated in most conversations -->
<!-- # Tardiff: age range only 17-20 months -->
<!-- # Soderstrom : age range only 5-13 months -->
<!-- # Bernstein : dataset is ver -->
<!-- # Davis: Cameron, Charlotte, Georgia -->
<!-- # !Davis: Ben -->
<!-- ``` -->

## Best Corpora (so far)
<!-- ```{r} -->

<!-- individual_children <- get_participants( -->
<!--   corpus = c("Providence", "MacWhinney", "Sachs", "ComptonPater"),  -->
<!--   role = c("target_child")) -->

<!-- individual_children |>  -->
<!--   select(name, corpus_name, min_age, max_age, collection_name) |> -->
<!--   filter(!is.na(name), collection_name == "Eng-NA") -->
<!-- ``` -->

<!-- ## Plots of cumulative_ppt trajectories for each function word, faceted by child -->
<!-- ```{r} -->
<!-- Child_relfreq <- english_tokens %>% -->
<!--   group_by(word, age, speaker, target_child_name, corpus_name) %>% -->
<!--   summarise(freq = n(), .groups = "drop") %>% -->
<!--   group_by(speaker, age, target_child_name) %>% -->
<!--   mutate(total = sum(freq), -->
<!--          relfreq = freq / sum(freq), -->
<!--          ppt = relfreq * 1000) %>% -->
<!--   group_by(word, speaker, target_child_name) %>% -->
<!--   arrange(age) %>% -->
<!--   mutate(cum_freq = cumsum(freq), -->
<!--          cum_total = cumsum(total), -->
<!--          cumulative_relfreq = cumsum(freq) / cumsum(total), -->
<!--          cumulative_ppt = cumulative_relfreq * 1000) %>% -->
<!--   ungroup() -->

<!-- plots_list <- lapply(function_words, function(fw) { -->
<!--   word_df <- Child_relfreq %>% -->
<!--     filter(word == fw) -->

<!--   # Filter to only include children speakers with at least 5 data points for this function word -->
<!--   child_counts <- word_df %>% -->
<!--     filter(speaker == "target_child") %>% -->
<!--     group_by(target_child_name) %>% -->
<!--     summarise(n_points = n()) %>% -->
<!--     filter(n_points >= 5) -->

<!--   word_df_filtered <- word_df %>% -->
<!--     filter(!(speaker == "target_child" & !(target_child_name %in% child_counts$target_child_name))) -->

<!--   if (nrow(word_df_filtered) == 0) { -->
<!--     return(NULL) -->
<!--   } -->
<!--   ggplot(word_df_filtered, aes(age, cumulative_ppt, color = speaker)) + -->
<!--     geom_point() + -->
<!--     geom_line() + -->
<!--     facet_wrap(~ target_child_name) + -->
<!--     theme_bw() + -->
<!--     labs(title = paste("Cumulative ppt for function word:", fw), -->
<!--          x = "Age (months)", -->
<!--          y = "Cumulative ppt", -->
<!--          color = "Speaker") -->
<!-- }) -->

<!-- for (p in plots_list) { -->
<!--   if (!is.null(p)) print(p) -->
<!-- } -->
<!-- ``` -->

## Plots for Providence (Lily, Naima), MacWhinney (Ross), Sachs (Naomi) for selected function words
```{r}
# Define the target children and the function words of interest
selected_children <- tibble(
  # target_child_name = c("Lily", "Naima", "Ross", "Naomi"),
  # corpus_name = c("Providence", "Providence", "MacWhinney", "Sachs")
  target_child_name = c("Adam", "Fraser"),
  corpus_name = c("Brown", "MPI-EVA-Manchester")
)
selected_function_words <- c("unless", "once", "if", "why", "all", "no", "by", "who", "on")
```


## Plots of cumulative_ppt trajectories for selected function words, faceted by selected children
```{r}
# Restrict the dataset to just the four target children and desired function words
Child_relfreq <- english_tokens %>%
  filter(
    word %in% selected_function_words,
    (target_child_name %in% selected_children$target_child_name) &
      (corpus_name %in% selected_children$corpus_name)
  ) %>%
  group_by(word, age, speaker, target_child_name, corpus_name) %>%
  summarise(freq = n(), .groups = "drop") %>%
  group_by(speaker, age, target_child_name) %>%
  mutate(total = sum(freq),
         relfreq = freq / sum(freq),
         ppt = relfreq * 1000) %>%
  group_by(word, speaker, target_child_name) %>%
  arrange(age) %>%
  mutate(cum_freq = cumsum(freq), 
         cum_total = cumsum(total), 
         cumulative_relfreq = cumsum(freq) / cumsum(total), 
         cumulative_ppt = cumulative_relfreq * 1000) %>%
  ungroup()

plots_list <- lapply(selected_function_words, function(fw) {
  word_df <- Child_relfreq %>%
    filter(word == fw)
  
  # Filter to only include children speakers with at least 5 data points for this function word
  child_counts <- word_df %>%
    filter(speaker == "target_child") %>%
    group_by(target_child_name) %>%
    summarise(n_points = n()) %>%
    filter(n_points >= 5)
  
  word_df_filtered <- word_df %>%
    filter(!(
      speaker == "target_child" &
      !(target_child_name %in% child_counts$target_child_name)
    ))
  
  if (nrow(word_df_filtered) == 0) {
    return(NULL)
  }
  ggplot(word_df_filtered, aes(age, cumulative_ppt, color = speaker)) +
    geom_point() +
    geom_line() +
    facet_wrap(~ target_child_name) +
    theme_bw() +
    labs(title = paste("Cumulative ppt for Function Word:", paste0(toupper(substring(fw, 1, 1)), substring(fw, 2))),
         x = "Age (months)",
         y = "Cumulative ppt",
         color = "Speaker")
})

for (p in plots_list) {
  if (!is.null(p)) print(p)
}
```










## Unused Code
<!-- # ## Plots of cumulative_ppt trajectories for each function word, faceted by child -->
<!-- # ```{r} -->
<!-- # Child_relfreq <- english_tokens %>% -->
<!-- #   group_by(word, age, speaker, target_child_name, corpus_name) %>% -->
<!-- #   summarise(freq = n(), .groups = "drop") %>% -->
<!-- #   group_by(speaker, age, target_child_name) %>% -->
<!-- #   mutate(total = sum(freq), -->
<!-- #          relfreq = freq / sum(freq), -->
<!-- #          ppt = relfreq * 1000) %>% -->
<!-- #   group_by(word, speaker, target_child_name) %>% -->
<!-- #   arrange(age) %>% -->
<!-- #   mutate(cum_freq = cumsum(freq), -->
<!-- #          cum_total = cumsum(total), -->
<!-- #          cumulative_relfreq = cumsum(freq) / cumsum(total), -->
<!-- #          cumulative_ppt = cumulative_relfreq * 1000) %>% -->
<!-- #   ungroup() -->
<!-- # -->
<!-- # plots_list <- lapply(function_words, function(fw) { -->
<!-- #   word_df <- Child_relfreq %>% -->
<!-- #     filter(word == fw) -->
<!-- #   if (nrow(word_df) == 0) { -->
<!-- #     return(NULL) -->
<!-- #   } -->
<!-- #   ggplot(word_df, aes(age, cumulative_ppt, color = speaker)) + -->
<!-- #     geom_point() + -->
<!-- #     geom_line() + -->
<!-- #     facet_wrap(~ target_child_name) + -->
<!-- #     theme_bw() + -->
<!-- #     labs(title = paste("Cumulative ppt for function word:", fw), -->
<!-- #          x = "Age (months)", -->
<!-- #          y = "Cumulative ppt", -->
<!-- #          color = "Speaker") -->
<!-- # }) -->
<!-- # -->
<!-- # for (p in plots_list) { -->
<!-- #   if (!is.null(p)) print(p) -->
<!-- # } -->